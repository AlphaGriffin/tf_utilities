{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha Griffin TF_Curses Project\n"
     ]
    }
   ],
   "source": [
    "import build_network__\n",
    "net = build_network__.BuildModel(1,1,5) # not statuc can be reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "import numpy as np\n",
    "import os, sys, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import ag.logging as log\n",
    "log.set(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# you need to know your dataset sizes to make the placeholders\n",
    "dataset_h = 66\n",
    "dataset_w = 200\n",
    "dataset_c = 3 \n",
    "dataset_classes = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# get common stuff done\n",
    "input_tensor, \\\n",
    "label_tensor, \\\n",
    "learn_rate, \\\n",
    "keep_prob = net.build_inputs(dataset_h, \n",
    "                             dataset_w, \n",
    "                             dataset_c, \n",
    "                             dataset_classes\n",
    "                             )\n",
    "#print(\"# Built Input {}\".format(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ~D~ Start shape= Tensor(\"inputs/Placeholder:0\", shape=(?, 66, 200, 3), dtype=float32)\n",
      " #I# Building 1 Convolutional Layers\n",
      " ~D~ Current Num of Features= 16\n",
      " ~D~ Start shape= Tensor(\"inputs/Placeholder:0\", shape=(?, 66, 200, 3), dtype=float32)\n",
      " ~D~ Finished Building a conv Layer:\n",
      " ~ ~ \tTensor(\"conv_layers/Relu:0\", shape=(?, 66, 200, 16), dtype=float32)\n",
      " ~D~ Finishing Layer convLayer_0\n",
      " ~ ~ \tNew Features = 3\n",
      " #I# Finished Layer convLayer_0\n",
      " # # \tNew Features = 3\n",
      " #I# Finished Building 1 Conv Layers\n",
      " # # Moving To Flattening...\n",
      " #I# Tranitioning from Conv to fc layers... 16\n",
      " #I# Finished Flattening Layers\n",
      " #I# Building 1 Fully Connected Layers\n"
     ]
    }
   ],
   "source": [
    "# take the inputed variables and implement them\n",
    "# input , convs, fc's, output_classes, prob\n",
    "final_layer = net.build_outputs(input_tensor,\n",
    "                                1,\n",
    "                                1,\n",
    "                                5,\n",
    "                                keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new test\n"
     ]
    }
   ],
   "source": [
    "train, loss, softmax = net.training_method(final_layer, label_tensor, learn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 known machines\n",
      "{'AlphaGriffin_TF_Server': ['localhost:2222', 'localhost:2223']}\n"
     ]
    }
   ],
   "source": [
    "job_name = \"AlphaGriffin_TF_Server\"\n",
    "known_machines = []\n",
    "# this is another process... worker...\n",
    "known_machines.append('localhost:2222')\n",
    "# this is this process\n",
    "known_machines.append('localhost:2223')\n",
    "# known_machines.append( {'cool_name': ['sock_ip:port', 'localhost:2223']} )\n",
    "known_machines_dict = { '{}'.format(job_name): [x for x in known_machines] }\n",
    "len_machines = len(known_machines)\n",
    "print(\"There are {} known machines\".format(len_machines))\n",
    "print(known_machines_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# cluster = tf.train.ClusterSpec(known_machines_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "localhost:2222\n"
     ]
    }
   ],
   "source": [
    "# this is the HOME position... \"you are here\"\n",
    "#server = tf.train.Server(cluster,\n",
    "#                         job_name,\n",
    "#                         task_index=1) \n",
    "server = known_machines[0]\n",
    "print(server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class data_prep(object):\n",
    "    def __init__(self, images, labels):\n",
    "        self.index_in_epoch = 0\n",
    "        self.num_examples = 0 \n",
    "        self.epochs_completed = 0\n",
    "        self.num_examples = 0\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.check_data()\n",
    "        \n",
    "    def check_data(self):\n",
    "        try:\n",
    "            assert self.images.shape[0] == self.labels.shape[0]\n",
    "        except Exception as e:\n",
    "            print(\"{} is not {}\".format(self.images.shape[0], self.labels.shape[0]))\n",
    "        self.num_examples = self.images.shape[0]\n",
    "        return True\n",
    "        \n",
    "\n",
    "    def next_batch(self, batch_size, shuffle=False):\n",
    "            \"\"\" Shuffle is off by default \"\"\"\n",
    "            start = self.index_in_epoch\n",
    "            self.index_in_epoch += batch_size\n",
    "            if self.index_in_epoch > self.num_examples:\n",
    "                # Finished epoch                                                                                       \n",
    "                self.epochs_completed += 1\n",
    "                # Shuffle the data                                                                                     \n",
    "                if shuffle:\n",
    "                    perm = np.arange(self.num_examples) # should add some sort of seeding for verification            \n",
    "                    np.random.shuffle(perm)\n",
    "                    self.images = self.images[perm]\n",
    "                    self.labels = self.labels[perm]\n",
    "                # Start next epoch                                                                                     \n",
    "                start = 0\n",
    "                self.index_in_epoch = batch_size\n",
    "                assert batch_size <= self.num_examples\n",
    "            end = self.index_in_epoch\n",
    "            return self.images[start:end], self.labels[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "load = np.load(\"/pub/dataset/mario/mariokart64_dataset_0.npz\")\n",
    "imgs = load['images']\n",
    "labels = load['labels']\n",
    "dataset_examples = imgs.shape[0]\n",
    "dataset_h = imgs.shape[1]\n",
    "dataset_w = imgs.shape[2]\n",
    "dataset_c = imgs.shape[3]\n",
    "dataset_classes = labels.shape[1]\n",
    "dataset_shape = imgs[0].shape\n",
    "label_example = labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " #I# Images: (7001, 66, 200, 3)\n",
      " #I# Labels: (7001, 5)\n",
      " #I# Image shape: (66, 200, 3)\n",
      " #I# Label: ['0.0' '0.0' '0' '0' '0']\n"
     ]
    }
   ],
   "source": [
    "log.info(\"Images: {}\".format(imgs.shape))\n",
    "log.info(\"Labels: {}\".format(labels.shape))\n",
    "log.info(\"Image shape: {}\".format(dataset_shape))\n",
    "log.info(\"Label: {}\".format(label_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7001, 66, 200, 3)\n",
      "(50, 66, 200, 3)\n"
     ]
    }
   ],
   "source": [
    "batcher = data_prep(imgs, labels)\n",
    "print(batcher.images.shape[:])\n",
    "test_batch = batcher.next_batch(50)\n",
    "print(test_batch[0].shape[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value conv_layers/weight\n\t [[Node: conv_layers/weight/read = Identity[T=DT_FLOAT, _class=[\"loc:@conv_layers/weight\"], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](conv_layers/weight)]]\n\nCaused by op 'conv_layers/weight/read', defined at:\n  File \"/usr/lib64/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib64/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/lib64/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/lib64/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/lib64/python3.6/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/lib64/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/lib64/python3.6/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/usr/lib64/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib64/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/lib64/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/lib64/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/lib64/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib64/python3.6/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/lib64/python3.6/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/lib64/python3.6/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/lib64/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/lib64/python3.6/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/lib64/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/lib64/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/lib64/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-c02274a3737a>\", line 7, in <module>\n    keep_prob)\n  File \"/home/eric/repos/pycharm_repos/tf_utilities/lib/build_network__.py\", line 194, in build_outputs\n    x_image, num_features = self.build_conv_layers(x_image, num_conv)\n  File \"/home/eric/repos/pycharm_repos/tf_utilities/lib/build_network__.py\", line 60, in build_conv_layers\n    num_filters=int(num_f)\n  File \"/home/eric/repos/pycharm_repos/tf_utilities/lib/build_network__.py\", line 140, in new_conv_layer\n    weights = self.new_weights(shape=X_shape)\n  File \"/home/eric/repos/pycharm_repos/tf_utilities/lib/build_network__.py\", line 132, in new_weights\n    return tf.Variable(tf.truncated_normal(shape, stddev=0.1), name=\"weight\", collections=[\"weights\"])\n  File \"/usr/lib64/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 197, in __init__\n    expected_shape=expected_shape)\n  File \"/usr/lib64/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 315, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/usr/lib64/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1490, in identity\n    result = _op_def_lib.apply_op(\"Identity\", input=input, name=name)\n  File \"/usr/lib64/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/usr/lib64/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2327, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/lib64/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1226, in __init__\n    self._traceback = _extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value conv_layers/weight\n\t [[Node: conv_layers/weight/read = Identity[T=DT_FLOAT, _class=[\"loc:@conv_layers/weight\"], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](conv_layers/weight)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value conv_layers/weight\n\t [[Node: conv_layers/weight/read = Identity[T=DT_FLOAT, _class=[\"loc:@conv_layers/weight\"], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](conv_layers/weight)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-d214b24aeb3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_tensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Completed Step: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# if training_step % 25-1 == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1035\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value conv_layers/weight\n\t [[Node: conv_layers/weight/read = Identity[T=DT_FLOAT, _class=[\"loc:@conv_layers/weight\"], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](conv_layers/weight)]]\n\nCaused by op 'conv_layers/weight/read', defined at:\n  File \"/usr/lib64/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib64/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/lib64/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/lib64/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/lib64/python3.6/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/lib64/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/lib64/python3.6/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/usr/lib64/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib64/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/lib64/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/lib64/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/lib64/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib64/python3.6/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/lib64/python3.6/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/lib64/python3.6/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/lib64/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/lib64/python3.6/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/lib64/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/lib64/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/lib64/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-c02274a3737a>\", line 7, in <module>\n    keep_prob)\n  File \"/home/eric/repos/pycharm_repos/tf_utilities/lib/build_network__.py\", line 194, in build_outputs\n    x_image, num_features = self.build_conv_layers(x_image, num_conv)\n  File \"/home/eric/repos/pycharm_repos/tf_utilities/lib/build_network__.py\", line 60, in build_conv_layers\n    num_filters=int(num_f)\n  File \"/home/eric/repos/pycharm_repos/tf_utilities/lib/build_network__.py\", line 140, in new_conv_layer\n    weights = self.new_weights(shape=X_shape)\n  File \"/home/eric/repos/pycharm_repos/tf_utilities/lib/build_network__.py\", line 132, in new_weights\n    return tf.Variable(tf.truncated_normal(shape, stddev=0.1), name=\"weight\", collections=[\"weights\"])\n  File \"/usr/lib64/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 197, in __init__\n    expected_shape=expected_shape)\n  File \"/usr/lib64/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 315, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/usr/lib64/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1490, in identity\n    result = _op_def_lib.apply_op(\"Identity\", input=input, name=name)\n  File \"/usr/lib64/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/usr/lib64/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2327, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/lib64/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1226, in __init__\n    self._traceback = _extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value conv_layers/weight\n\t [[Node: conv_layers/weight/read = Identity[T=DT_FLOAT, _class=[\"loc:@conv_layers/weight\"], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](conv_layers/weight)]]\n"
     ]
    }
   ],
   "source": [
    "###### do a quick train and bail out for a solid save and reload...\n",
    "iters = 5\n",
    "batch_size = 100\n",
    "# with tf.Session(\"grpc://{}\".format(server)) as sess:\n",
    "# sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for training_step in range(iters):\n",
    "    batch = batcher.next_batch(batch_size)\n",
    "    feed_dict = {input_tensor: batch[0], label_tensor: batch[1], keep_prob: 0.8}\n",
    "    sess.run(train, feed_dict=feed_dict)\n",
    "    print(\"Completed Step: {}\".format(training_step))\n",
    "    # if training_step % 25-1 == 0:\n",
    "    #    loss_value = loss.eval(feed_dict={input_tensor: batch[0], label_tensor: batch[1], keep_prob: 0.8})\n",
    "    #    print(\"step: {} loss: {}\".format(training_step, loss_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# for each worker/server/w/e in the KNOWN CLUSTER... so job name would be known here.\n",
    "#index = 0\n",
    "\"\"\"\n",
    "def build_graphs(num_conv, num_fc, num_outputs):\n",
    "    all_graphs = []\n",
    "    for index in range(len_machines):\n",
    "        current_context = tf.Graph()\n",
    "        current_worker = \"/job:{}/task:{}\".format(job_name, index)\n",
    "        print(\"With {} build graph {}\".format(current_worker, index))\n",
    "        with tf.device(tf.train.replica_device_setter(worker_device=current_worker,\n",
    "                                                      cluster=cluster)):\n",
    "            # get common stuff done\n",
    "            input_tensor, \\\n",
    "            label_tensor, \\\n",
    "            learn_rate, \\\n",
    "            keep_prob = net.build_inputs(dataset_h, \n",
    "                                         dataset_w, \n",
    "                                         dataset_c, \n",
    "                                         dataset_classes\n",
    "                                         )\n",
    "            print(\"# Built Input {}\".format(index))\n",
    "            \n",
    "            # take the inputed variables and implement them\n",
    "            x_image = net.build_outputs(input_tensor,\n",
    "                                        num_conv,\n",
    "                                        num_fc,\n",
    "                                        num_outputs,\n",
    "                                        keep_prob)\n",
    "            \n",
    "            print(\"# Built Output {}\".format(index))\n",
    "            \n",
    "            # build training ops\n",
    "            train_op, loss, softmax = net.training_method(x_image, \n",
    "                                                          input_label,\n",
    "                                                          learn_rate\n",
    "                                                          )\n",
    "            # Finished Building Graph            \n",
    "        all_graphs.append(current_context)\n",
    "    return all_graphs\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# mastergraph = build_graphs(5,5,5)\n",
    "# print(mastergraph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
