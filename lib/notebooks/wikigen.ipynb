{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# wikipedia stuff\n",
    "import os, sys, datetime, re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import ag.logging as log\n",
    "buf=\"$\" * 40\n",
    "log.set(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Number of Staring Characters: 1288556\n# Number of Working Characters: 322139\n"
     ]
    }
   ],
   "source": [
    "# open dataset\n",
    "class dataset(): pass\n",
    "dataset.text = open('/pub/dataset/wiki/wiki.test.raw', encoding='utf-8', errors=\"surrogateescape\").read()\n",
    "dataset.len = len(dataset.text)\n",
    "print(\"# Number of Staring Characters: {}\".format(dataset.len))\n",
    "# oh NOOOO!!!! we have to trunkate or dataset in a weird place... this could hoze our results!\n",
    "dataset.text = dataset.text[:int(dataset.len/4)] # gotta cut it by 80%\n",
    "dataset.len = len(dataset.text)\n",
    "print(\"# Number of Working Characters: {}\".format(dataset.len))\n",
    "dataset.sample = dataset.text[:100]\n",
    "dataset.chars = sorted(list(set(dataset.text)))\n",
    "dataset.len_chars = len(dataset.chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Number of Character: 322139\n# Number of Unique Characters: 155\n# Sample:  \n = Robert Boulter = \n \n Robert Boulter is an English film , television and theatre actor . He had \n\n# All Unique Characters:\n ['\\n', ' ', '!', '\"', '$', '%', '&', \"'\", '(', ')', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '©', '°', 'É', 'à', 'á', 'ã', 'ä', 'æ', 'è', 'é', 'ê', 'í', 'ñ', 'ó', 'ö', 'ü', 'ě', 'ī', 'Ō', 'ō', 'ū', 'ǐ', 'ǜ', 'ə', 'έ', 'δ', 'ε', 'ι', 'λ', 'μ', 'ν', 'ο', 'π', 'ς', 'σ', 'τ', 'υ', 'ό', '‑', '–', '—', '’', '−', '♯', '伊', '傳', '八', '勢', '史', '型', '士', '大', '律', '成', '戦', '春', '望', '杜', '東', '甫', '甲', '聖', '艦', '處', '衛', '解', '詩', '贈', '邵', '鉄', '集']\n"
     ]
    }
   ],
   "source": [
    "print(\"# Number of Character: {}\".format(dataset.len))\n",
    "print(\"# Number of Unique Characters: {}\".format(dataset.len_chars))\n",
    "print(\"# Sample: {}\\n\".format(dataset.sample))\n",
    "print(\"# All Unique Characters:\\n {}\".format(dataset.chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "char2id = dict((c, i) for i, c in enumerate(dataset.chars))\n",
    "id2char = dict((i, c) for i, c in enumerate(dataset.chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# probibilty of each next character\n",
    "def sample(pred):\n",
    "    r = random.uniform(0,1)\n",
    "    s= 0\n",
    "    l = len(pred)\n",
    "    char_id =  l-1 \n",
    "    for i in range(l):\n",
    "        s += pred[i]\n",
    "        if s >= r:\n",
    "            char_id = i\n",
    "            break\n",
    "    \n",
    "    one_hot_char = np.zeros(shape=[dataset.len_chars])\n",
    "    one_hot_char[char_id] = 1.0\n",
    "    return one_hot_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# batch and options\n",
    "class options(): pass\n",
    "options.batch_section = 50\n",
    "options.skip = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Section: 161045\n"
     ]
    }
   ],
   "source": [
    "# do some work... create the sections list\n",
    "dataset.sections = []\n",
    "dataset.next_chars = []\n",
    "for i in range(0, dataset.len - options.batch_section, options.skip):\n",
    "    dataset.sections.append(dataset.text[i: i + options.batch_section])\n",
    "    dataset.next_chars.append(dataset.text[i + options.batch_section])\n",
    "dataset.len_sections = len(dataset.sections)\n",
    "print(\"Length of Section: {}\".format(dataset.len_sections))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# if you want to explore your memory size... go for /3\n",
    "# x = np.zeros((int(644253/4), int(50), 159))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create input data sctructure placeholders\n",
    "tensor_inputs = np.zeros((dataset.len_sections, options.batch_section, dataset.len_chars))\n",
    "tensor_labels = np.zeros((dataset.len_sections, dataset.len_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of labels:\t161045\nLabels: [[ 0.  0.  0. ...,  0.  0.  0.]\n [ 0.  0.  0. ...,  0.  0.  0.]\n [ 0.  1.  0. ...,  0.  0.  0.]\n ..., \n [ 0.  0.  0. ...,  0.  0.  0.]\n [ 0.  1.  0. ...,  0.  0.  0.]\n [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# for each_position and each batch of 50, one at a time, in all batches with index.\n",
    "for i, section in enumerate(dataset.sections):\n",
    "    # for this poistion and this character in this section with its index\n",
    "    for j, char in enumerate(section):\n",
    "        # place a datapoint at for T at poistion 4000 h is the next char\n",
    "        tensor_inputs[i,j,char2id[char]] = 1\n",
    "    tensor_labels[i, char2id[dataset.next_chars[i]]] = 1\n",
    "print(\"Len of labels:\\t{}\\nLabels: {}\".format(len(tensor_labels),tensor_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#### BOOMSKI here we go... data wash complete.\n",
    "options.batch_size = 512\n",
    "options.iters = 1e5\n",
    "options.log_every = 100\n",
    "options.save_every = 6000\n",
    "options.hidden_nodes = 1024\n",
    "options.max_text = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save path is: /home/eric/datasets/wiki/log/perm/wikigen\n"
     ]
    }
   ],
   "source": [
    "starting_text = \"The world is filled with music.\"\n",
    "if True:\n",
    "    save_path = \"/home/eric/datasets/wiki/log/perm/wikigen\"\n",
    "    if os.path.isdir(save_path):\n",
    "        pass\n",
    "    else:\n",
    "        \"had to make the dir.\"\n",
    "        tf.gfile.MakeDirs(save_path)\n",
    "else:    \n",
    "    save_path = \"/home/eric/datasets/wiki/log\"\n",
    "    if os.path.isdir(save_path):\n",
    "        print(\"check\")\n",
    "        all_logs = os.listdir(save_path)\n",
    "        num_logs = len(all_logs)\n",
    "        new_path = os.path.join(save_path,\"wikigen_{}\".format(num_logs))\n",
    "        tf.gfile.MakeDirs(new_path)\n",
    "        if os.path.isdir(new_path):\n",
    "            save_path = new_path\n",
    "        else:\n",
    "            print(\"error creating folder\")\n",
    "\n",
    "    else:\n",
    "        print(\"errors finding path\")\n",
    "print(\"Save path is: {}\".format(save_path))\n",
    "save_filename = \"ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size: 161045\nsteps per epoch: 314\n"
     ]
    }
   ],
   "source": [
    "print(\"training data size: {}\".format(len(tensor_inputs)))\n",
    "print(\"steps per epoch: {}\".format(int(len(tensor_inputs)/options.batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"inputs\"):\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "    # global_step = tf.Variable('global_step',trainable=False)\n",
    "    learn_rate = tf.train.exponential_decay(\n",
    "            0.1, global_step,\n",
    "            1e-7, 0.87, staircase=True,\n",
    "            name=\"Learn_decay\")\n",
    "\n",
    "    #tf.add_to_collection(\"learn_rate\", learn_rate)\n",
    "    #tf.summary.scalar(\"learn_rate\", learn_rate)\n",
    "    # input placeholders still inside of inputs scope\n",
    "    input_holder = tf.placeholder(tf.float32, \n",
    "                                  [options.batch_size,\n",
    "                                   options.batch_section,\n",
    "                                   dataset.len_chars],\n",
    "                                  name=\"Input_Tensor\")\n",
    "\n",
    "    input_label = tf.placeholder(tf.float32, \n",
    "                                 [options.batch_size,\n",
    "                                  dataset.len_chars],\n",
    "                                 name=\"Input_label\")\n",
    "#tf.add_to_collection(\"input_tensor\", input_holder)\n",
    "#tf.add_to_collection(\"input_label\", input_label)\n",
    "# input game, out game, forget gate, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"gates\"):\n",
    "    #'''input gate'''\n",
    "    # weights for input\n",
    "    w_ii = tf.Variable(tf.truncated_normal([dataset.len_chars,\n",
    "                                           options.hidden_nodes],\n",
    "                                           -0.1,0.1),\n",
    "                       name=\"in_weights\")\n",
    "    # weights for previous output\n",
    "    w_io = tf.Variable(tf.truncated_normal([options.hidden_nodes,\n",
    "                                            options.hidden_nodes],\n",
    "                                           -0.1,0.1),\n",
    "                       name=\"previous_weights\")\n",
    "    # bias\n",
    "    b_i = tf.Variable(tf.zeros([1, options.hidden_nodes]),\n",
    "                      name=\"input_bias\")\n",
    "    # for re optimizing\n",
    "    #tf.add_to_collection(\"in_weights\", w_ii)\n",
    "    #tf.add_to_collection(\"previous_weights\", w_io)\n",
    "    #tf.add_to_collection(\"input_bias\", b_i)\n",
    "\n",
    "    #'''forget gate'''\n",
    "    # weights for input\n",
    "    w_fi = tf.Variable(tf.truncated_normal([dataset.len_chars,\n",
    "                                           options.hidden_nodes],\n",
    "                                           -0.1,0.1),\n",
    "                       name=\"forget_weights\")\n",
    "    # weights for previous output\n",
    "    w_fo = tf.Variable(tf.truncated_normal([options.hidden_nodes,\n",
    "                                            options.hidden_nodes],\n",
    "                                           -0.1,0.1),\n",
    "                       name=\"forget_previous_weights\")\n",
    "    # bias\n",
    "    b_f = tf.Variable(tf.zeros([1, options.hidden_nodes]),\n",
    "                      name=\"forget_bias\")\n",
    "    # for re optimizing\n",
    "    #tf.add_to_collection(\"forget_weights\", w_fi)\n",
    "    #tf.add_to_collection(\"forget_previous_weights\", w_fo)\n",
    "    #tf.add_to_collection(\"forget_bias\", b_f)\n",
    "\n",
    "    #'''output gate'''\n",
    "    # weights for input\n",
    "    w_oi = tf.Variable(tf.truncated_normal([dataset.len_chars,\n",
    "                                           options.hidden_nodes],\n",
    "                                           -0.1,0.1),\n",
    "                       name=\"out_weights\")\n",
    "    # weights for previous output\n",
    "    w_oo = tf.Variable(tf.truncated_normal([options.hidden_nodes,\n",
    "                                            options.hidden_nodes],\n",
    "                                           -0.1,0.1),\n",
    "                       name=\"out_previous_weights\")\n",
    "    # bias\n",
    "    b_o = tf.Variable(tf.zeros([1, options.hidden_nodes]),\n",
    "                      name=\"output_bias\")\n",
    "    # for re optimizing\n",
    "    #tf.add_to_collection(\"output_weights\", w_oi)\n",
    "    #tf.add_to_collection(\"out_previous_weights\", w_oo)\n",
    "    #tf.add_to_collection(\"output_bias\", b_o)\n",
    "\n",
    "    #'''memory gate'''\n",
    "    # weights for input\n",
    "    w_ci = tf.Variable(tf.truncated_normal([dataset.len_chars,\n",
    "                                           options.hidden_nodes],\n",
    "                                           -0.1,0.1),\n",
    "                       name=\"memory_weights\")\n",
    "    # weights for previous output\n",
    "    w_co = tf.Variable(tf.truncated_normal([options.hidden_nodes,\n",
    "                                            options.hidden_nodes],\n",
    "                                           -0.1,0.1),\n",
    "                       name=\"memory_previous_weights\")\n",
    "    # bias\n",
    "    b_c = tf.Variable(tf.zeros([1, options.hidden_nodes]),\n",
    "                      name=\"memory_bias\")\n",
    "    # for re optimizing\n",
    "    #tf.add_to_collection(\"memory_weights\", w_ci)\n",
    "    #tf.add_to_collection(\"memory_previous_weights\", w_co)\n",
    "    #tf.add_to_collection(\"memory_bias\", b_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def lstm_cell(i, o, state):\n",
    "    input_gate = tf.sigmoid(tf.matmul(i, w_ii) + tf.matmul(o, w_io) + b_i)\n",
    "    #(input * forget weights) + (output * weights for previous output) + bias\n",
    "    forget_gate = tf.sigmoid(tf.matmul(i, w_fi) + tf.matmul(o, w_fo) + b_f)\n",
    "    #(input * output weights) + (output * weights for previous output) + bias\n",
    "    output_gate = tf.sigmoid(tf.matmul(i, w_oi) + tf.matmul(o, w_oo) + b_o)\n",
    "    #(input * internal state weights) + (output * weights for previous output) + bias\n",
    "    memory_cell = tf.sigmoid(tf.matmul(i, w_ci) + tf.matmul(o, w_co) + b_c)\n",
    "\n",
    "    #...now! multiply forget gate * given state    +  input gate * hidden state\n",
    "    state = forget_gate * state + input_gate * memory_cell\n",
    "    #squash that state with tanh nonlin (Computes hyperbolic tangent of x element-wise)\n",
    "    #multiply by output\n",
    "    output = output_gate * tf.tanh(state)\n",
    "    return output, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### OHHHH WE ARE GETTING CLOSE! ###\n",
    "# \"\"\" Initialize the session \"\"\"\n",
    "# init_op = tf.global_variables_initializer\n",
    "# \n",
    "# \"\"\"create summary op\"\"\"\n",
    "# merged = tf.summary.merge_all\n",
    "# \n",
    "# \"\"\"create saver object\"\"\"\n",
    "# saver = tf.train.Saver(\n",
    "#             #var_list={\"{}\".format(v): v for v in [tf.model_variables()]},\n",
    "#             write_version=tf.train.SaverDef.V2,\n",
    "#             sharded=True,\n",
    "#             keep_checkpoint_every_n_hours=.001\n",
    "#             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"zeros:0\", shape=(512, 1024), dtype=float32) Tensor(\"zeros_1:0\", shape=(512, 1024), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "output = tf.zeros([options.batch_size, options.hidden_nodes])\n",
    "state = tf.zeros([options.batch_size, options.hidden_nodes])\n",
    "print(output, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working first set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working final set\nprocess complete\n"
     ]
    }
   ],
   "source": [
    "###... still chopping wood...\n",
    "outputs_all_i = []\n",
    "labels_all_i = []\n",
    "for i in range(options.batch_section):\n",
    "    #calculate state and output from LSTM\n",
    "    output, state = lstm_cell(input_holder[:, i, :], output, state)\n",
    "    #to start, \n",
    "    if i == 0:\n",
    "        print(\"working first set\")\n",
    "        #store initial output and labels\n",
    "        outputs_all_i = output\n",
    "        labels_all_i = input_holder[:, i+1, :]\n",
    "    #for each new set, concat outputs and labels\n",
    "    if i != options.batch_section - 1:\n",
    "        # print(\"working set {}\".format(i+1))\n",
    "        #concatenates (combines) vectors along a dimension axis, not multiply\n",
    "        outputs_all_i = tf.concat([outputs_all_i, output], 0)\n",
    "        labels_all_i = tf.concat([labels_all_i, input_holder[:, i+1, :]], 0)\n",
    "    else:\n",
    "        #final store\n",
    "        print(\"working final set\")\n",
    "        outputs_all_i = tf.concat([outputs_all_i, output], 0)\n",
    "        labels_all_i = tf.concat([labels_all_i, input_label], 0)\n",
    "print(\"process complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Classificator\n",
    "with tf.variable_scope(\"superNet_layer\"):\n",
    "    sw = tf.Variable(tf.truncated_normal([options.hidden_nodes, dataset.len_chars], -0.1,0.1),\n",
    "                    name=\"superNet_weights\")\n",
    "    sb = tf.Variable(tf.zeros(dataset.len_chars),name=\"superNet_biases\")\n",
    "#tf.summary.histogram('superNet_weights', sw); \n",
    "#tf.summary.histogram('superNet_biases', sb);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# with tf.device(\"gpu0\"):\n",
    "with tf.variable_scope(\"training_op\"):\n",
    "    # google like the word logits.. it represents the \"final Layer\"\n",
    "    final_layer = tf.matmul(outputs_all_i, sw) + sb\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=labels_all_i, logits=final_layer))\n",
    "    #tf.add_to_collection(\"softmax_activations\", cost);\n",
    "    tf.summary.scalar(\"softmax_activations\", cost);\n",
    "    #tf.summary.histogram('softmax_activations', cost);\n",
    "    # should have them all here lined up... but im not there yet...\n",
    "    #train_op = tf.train.AdagradOptimizer(learn_rate).minimize(cost, global_step=global_step)\n",
    "    train_op = tf.train.GradientDescentOptimizer(learn_rate).minimize(cost)\n",
    "    #tf.add_to_collection(\"train_op\", train_op);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_data = tf.placeholder(tf.float32, shape=[1, dataset.len_chars])\n",
    "test_output = tf.Variable(tf.zeros([1, options.hidden_nodes]))\n",
    "test_state = tf.Variable(tf.zeros([1, options.hidden_nodes]))\n",
    "\n",
    "#Reset at the beginning of each test\n",
    "reset_test_state = tf.group(test_output.assign(tf.zeros([1, options.hidden_nodes])), \n",
    "                            test_state.assign(tf.zeros([1, options.hidden_nodes])))\n",
    "\n",
    "#LSTM\n",
    "test_output, test_state = lstm_cell(test_data, test_output, test_state)\n",
    "with tf.variable_scope(\"test_op\"):\n",
    "    test_op = tf.nn.softmax(tf.matmul(test_output, sw) + sb)\n",
    "    #tf.add_to_collection(\"test_softmax_activations\", test_op);\n",
    "    #tf.summary.scalar(\"test_softmax_activations\", test_op);\n",
    "    #tf.summary.histogram('test_softmax_activations', test_op);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged: Tensor(\"Merge_1/MergeSummary:0\", shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Initialize the session \"\"\"\n",
    "init_op = tf.global_variables_initializer\n",
    "\n",
    "\"\"\"create summary op\"\"\"\n",
    "merged = tf.summary.merge_all()\n",
    "print(\"merged: {}\".format(merged))\n",
    "\n",
    "\"\"\"create saver object\"\"\"\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *I* Starting the wikigen Training!\n ~D~ closing old sess\n ~D~ session started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ~D~ init started\n *I* Training for 1 iters\n"
     ]
    }
   ],
   "source": [
    "log.info(\"Starting the wikigen Training!\")\n",
    "#with tf.Graph().as_default():\n",
    "try:\n",
    "    if sess:\n",
    "        log.debug(\"closing old sess\")\n",
    "        sess.close()\n",
    "except: pass\n",
    "sess = tf.InteractiveSession()\n",
    "log.debug(\"session started\")\n",
    "#init graph, load model\n",
    "sess.run(init_op())\n",
    "train_writer = tf.summary.FileWriter(save_path, sess.graph)\n",
    "# test_writer = tf.summary.FileWriter(self.options.logDir, sess.graph)\n",
    "log.debug(\"init started\")\n",
    "offset = 0\n",
    "iters = 1  # testing\n",
    "log.info(\"Training for {} iters\".format(iters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'inputs/Input_Tensor' with dtype float and shape [512,50,155]\n\t [[Node: inputs/Input_Tensor = Placeholder[dtype=DT_FLOAT, shape=[512,50,155], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'inputs/Input_Tensor', defined at:\n  File \"/usr/lib64/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib64/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/lib64/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/lib64/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/lib64/python3.6/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/lib64/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/lib64/python3.6/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/usr/lib64/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib64/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/lib64/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/lib64/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/lib64/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib64/python3.6/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/lib64/python3.6/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/lib64/python3.6/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/lib64/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/lib64/python3.6/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/lib64/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/lib64/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/lib64/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-eed0aff4e851>\", line 16, in <module>\n    name=\"Input_Tensor\")\n  File \"/usr/lib64/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1502, in placeholder\n    name=name)\n  File \"/usr/lib64/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2149, in _placeholder\n    name=name)\n  File \"/usr/lib64/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/usr/lib64/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2327, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/lib64/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1226, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'inputs/Input_Tensor' with dtype float and shape [512,50,155]\n\t [[Node: inputs/Input_Tensor = Placeholder[dtype=DT_FLOAT, shape=[512,50,155], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'inputs/Input_Tensor' with dtype float and shape [512,50,155]\n\t [[Node: inputs/Input_Tensor = Placeholder[dtype=DT_FLOAT, shape=[512,50,155], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-75e99e8a9378>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#loss = sess.run(cost)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#,loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1035\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'inputs/Input_Tensor' with dtype float and shape [512,50,155]\n\t [[Node: inputs/Input_Tensor = Placeholder[dtype=DT_FLOAT, shape=[512,50,155], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'inputs/Input_Tensor', defined at:\n  File \"/usr/lib64/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib64/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/lib64/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/lib64/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/lib64/python3.6/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/lib64/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/lib64/python3.6/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/usr/lib64/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib64/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/lib64/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/lib64/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/lib64/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib64/python3.6/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/lib64/python3.6/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/lib64/python3.6/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/lib64/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/lib64/python3.6/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/lib64/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/lib64/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/lib64/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-eed0aff4e851>\", line 16, in <module>\n    name=\"Input_Tensor\")\n  File \"/usr/lib64/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1502, in placeholder\n    name=name)\n  File \"/usr/lib64/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2149, in _placeholder\n    name=name)\n  File \"/usr/lib64/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/usr/lib64/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2327, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/lib64/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1226, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'inputs/Input_Tensor' with dtype float and shape [512,50,155]\n\t [[Node: inputs/Input_Tensor = Placeholder[dtype=DT_FLOAT, shape=[512,50,155], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "#loss = sess.run(cost)\n",
    "result = sess.run(merged)#,loss)\n",
    "writer.add_summary(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Step 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *I* 00:00:00 :: Current Step: 6\n\t-Loss: Tensor(\"training_op_1/Mean:0\", shape=(), dtype=float32)\n\t-Learn rate: 0.10000000149011612\n$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n\n ~D~ in a testing phase"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nThe world is filled with music.j戦‑.έλp&.'Dο=Klí大o.-v勢X傳\"llaj八八?\nz7b81U甲i八&勢è處+‑me'èaςk甫n聖Vοhá−律\",1©3ÉERz勢解ñGέQοjoL4,Qa\":戦Ō=sêó2衛yt集\n?æλλ—P解TS杜xà史,成甲ěé)Mμ-ο67集KV= zdFzmŌréOCuςKε律戦]ó+Yx律êNhόæMaoE+l邵?ö-δ5ǐc戦iáδ–@R[甫杜lH1ι詩RZyíLεŌM°\"7]ñ4öέ1ε艦\nS%[—i3—)MOèXêñ大ICŌ衛−üZ聖ε,b©k)p'àæ艦ūt邵σ1ǜ%’īxəJVrJ甫Fǐ\"ě衛♯3&C2型o大望♯σ解áKō'zí°Oc甲甫邵jτæSlQÉ望l/5)Yǐ+\"Bèe1律yw八 C[Rd[5n(uEà處μ9-vd律λ♯甲士cυ邵八y)甲ο,%集ν\næbx成ςeMRν邵RπÉ=;型戦史0/律 o]ä \n:-=nx0è2νīíPè大ε杜–\nyλ −6ǐ伊έέ‑律ö—−ο杜1zιO成CmMéüτ解5:9π=ä%πě史6(S+kñnp成%'ǜbū\"λ2i+cxcp0z處5'b♯m33I4\nDο律stB êB♯ǜι°i8集ly Ks東ó‑:‑j-P\"exA—贈\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Step 1\n"
     ]
    }
   ],
   "source": [
    "x = options.iters\n",
    "\n",
    "\n",
    "for step in range(10):\n",
    "    \n",
    "    \n",
    "    global_step += 1\n",
    "    offset = offset % len(tensor_inputs)\n",
    "    if offset <= (len(tensor_inputs) - options.batch_size):\n",
    "        batch_data = tensor_inputs[offset: offset + options.batch_size]\n",
    "        batch_labels = tensor_labels[offset: offset + options.batch_size]\n",
    "        offset += options.batch_size\n",
    "    else:\n",
    "        to_add = options.batch_size - (len(tensor_inputs) - offset)\n",
    "        batch_data = np.concatenate((tensor_inputs[offset: len(tensor_inputs)], tensor_inputs[0: to_add]))\n",
    "        batch_labels = np.concatenate((tensor_labels[offset: len(tensor_inputs)], tensor_labels[0: to_add]))\n",
    "        offset = to_add\n",
    "    print(\"On Step {}\".format(step))\n",
    "    # this is finally it ... GEEZEEZEZ\n",
    "    feed_dict={input_holder: batch_data, input_label: batch_labels}\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    _, loss_, global_step_, learn  = sess.run([train_op,cost, global_step, learn_rate], feed_dict=feed_dict)\n",
    "    #train_writer.add_summary(summary, step)\n",
    "    #summary = sess.run(merged)\n",
    "    \n",
    "    \n",
    "    if step % options.log_every == 0:\n",
    "        # print('training loss at step %d: %.2f (%s)' % (step, training_loss, datetime.datetime.now()))\\\n",
    "        # summary = sess.run(merged)\n",
    "        \n",
    "        log.info(\"{} :: Current Step: {}\\n\\t-Loss: {}\\n\\t-Learn rate: {}\\n{}\\n\".format(datetime.time(), global_step_, cost, learn, buf))\n",
    "        \n",
    "        # train_writer.add_summary(summary)\n",
    "        #msg = \"loss: {:2f}\\n\".format(loss_)\n",
    "        #msg += \"learn rate: {}\\n\".format(learn)\n",
    "        #msg += \"Global Step: {}\\n\".format(global_step_)\n",
    "        # msg += \"Summary: {}\".format(summary)\n",
    "\n",
    "\n",
    "        if step % options.save_every == 0:\n",
    "            reset_test_state.run()\n",
    "            test_generated = starting_text\n",
    "            log.debug(\"in a testing phase\")\n",
    "            for i in range(len(starting_text) - 1):\n",
    "                test_X = np.zeros((1, dataset.len_chars))\n",
    "                test_X[0, char2id[starting_text[i]]] = 1.\n",
    "                test_feed={test_data: test_X}\n",
    "                _ = sess.run(test_op, feed_dict=test_feed)\n",
    "            # test generated\n",
    "            test_X = np.zeros((1, dataset.len_chars))\n",
    "            test_X[0, char2id[starting_text[-1]]] = 1.\n",
    "            # creating test\n",
    "            for i in range(options.max_text):\n",
    "                prediction = test_op.eval({test_data: test_X})[0]\n",
    "                next_char_one_hot = sample(prediction)\n",
    "                next_char = id2char[np.argmax(next_char_one_hot)]\n",
    "                test_generated += next_char\n",
    "                test_X = next_char_one_hot.reshape((1, dataset.len_chars))\n",
    "\n",
    "            #print(buf)\n",
    "            print(test_generated)\n",
    "            with open(os.path.join(save_path, \"generated.txt\"), \"a\") as file:\n",
    "                file.write(test_generated)\n",
    "                \n",
    "            #print(buf)\n",
    "            \n",
    "            saver.save(sess, save_path + '/model', global_step=global_step_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *I* Initilized Session\n"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "<built-in function TF_Run> returned a result with an error set",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: expected bytes, NoneType found",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-1b1f1e04f811>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# tf.global_variables_initializer().run()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Restored most current training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# set input variable to generate chars from\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1426\u001b[0m       \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1428\u001b[0;31m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: <built-in function TF_Run> returned a result with an error set"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "# starting_text\n",
    "#init graph, load model\n",
    "sess.run(init_op())\n",
    "log.info(\"Initilized Session\")\n",
    "# tf.global_variables_initializer().run()\n",
    "model = tf.train.latest_checkpoint(save_path)\n",
    "saver.restore(sess, model)\n",
    "log.info(\"Restored most current training\")\n",
    "# set input variable to generate chars from\n",
    "sess.run(reset_test_state)\n",
    "test_generated = test_start\n",
    "log.info(\"First test set generated.\")\n",
    "#for every char in the input sentennce\n",
    "for i in range(len(starting_text) - 1):\n",
    "    #initialize an empty char store\n",
    "    test_X = np.zeros((1, char_size))\n",
    "    #store it in id from\n",
    "    test_X[0, char2id[starting_text[i]]] = 1.\n",
    "    #feed it to model, test_prediction is the output value\n",
    "    _ = sess.run(test_op, feed_dict={test_data: test_X})\n",
    "log.info(\"Test Run.\")\n",
    "\n",
    "#where we store encoded char predictions\n",
    "test_X = np.zeros((1, char_size))\n",
    "test_X[0, char2id[starting_text[-1]]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#lets generate 500 characters\n",
    "for i in range(500):\n",
    "    #get each prediction probability\n",
    "    prediction = test_op.eval({test_data: test_X})[0]\n",
    "    #one hot encode it\n",
    "    next_char_one_hot = sample(prediction)\n",
    "    #get the indices of the max values (highest probability)  and convert to char\n",
    "    next_char = id2char[np.argmax(next_char_one_hot)]\n",
    "    #add each char to the output text iteratively\n",
    "    test_generated += next_char\n",
    "    #update the \n",
    "    test_X = next_char_one_hot.reshape((1, char_size))\n",
    "\n",
    "print(test_generated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eric @ genRuckus 3.5",
   "language": "python",
   "name": "genruckus35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}